{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project — Hate Speech Detection\n",
    "## Notebook 1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Dataset:** Davidson Hate Speech Dataset (labeled_data.csv)  \n",
    "**Goal:** Understand the structure, class distribution, text patterns, and annotator agreement before modelling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup — Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optional: word cloud (install with: pip install wordcloud)\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    WORDCLOUD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "    print('WordCloud not installed. Run: pip install wordcloud')\n",
    "\n",
    "# Plot style\n",
    "sns.set_theme(style='whitegrid', palette='muted')\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "# Class label mapping — we'll reuse this throughout\n",
    "CLASS_LABELS = {0: 'Hate Speech', 1: 'Offensive', 2: 'Neither'}\n",
    "CLASS_COLORS = {0: '#D62728', 1: '#FF7F0E', 2: '#2CA02C'}\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load & Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset — update the path if needed\n",
    "df = pd.read_csv('labeled_data.csv')\n",
    "\n",
    "# Drop unnamed index column\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Map class numbers to readable labels\n",
    "df['class_label'] = df['class'].map(CLASS_LABELS)\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Columns: {df.columns.tolist()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data quality check\n",
    "print('--- Data Types ---')\n",
    "print(df.dtypes)\n",
    "print()\n",
    "print('--- Missing Values ---')\n",
    "print(df.isnull().sum())\n",
    "print()\n",
    "print('--- Duplicate Rows ---')\n",
    "print(f'Duplicates: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column descriptions\n",
    "# - count:              number of annotators who labeled this tweet\n",
    "# - hate_speech:        how many annotators labeled it as hate speech\n",
    "# - offensive_language: how many annotators labeled it as offensive\n",
    "# - neither:            how many annotators labeled it as neither\n",
    "# - class:              final majority-vote label (0=hate speech, 1=offensive, 2=neither)\n",
    "# - tweet:              raw tweet text\n",
    "\n",
    "print('Annotator count distribution:')\n",
    "print(df['count'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Class Distribution\n",
    "\n",
    "Understanding how balanced (or imbalanced) the dataset is — this directly affects how we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['class'].value_counts().sort_index()\n",
    "class_pct = (class_counts / len(df) * 100).round(1)\n",
    "\n",
    "print('Class Distribution:')\n",
    "for cls, name in CLASS_LABELS.items():\n",
    "    print(f'  {name}: {class_counts[cls]:,} tweets ({class_pct[cls]}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar chart\n",
    "colors = [CLASS_COLORS[i] for i in sorted(CLASS_LABELS.keys())]\n",
    "bars = axes[0].bar(\n",
    "    [CLASS_LABELS[i] for i in sorted(CLASS_LABELS.keys())],\n",
    "    [class_counts[i] for i in sorted(CLASS_LABELS.keys())],\n",
    "    color=colors, edgecolor='white', linewidth=1.5\n",
    ")\n",
    "axes[0].set_title('Tweet Count by Class', fontsize=14, fontweight='bold', pad=15)\n",
    "axes[0].set_ylabel('Number of Tweets')\n",
    "for bar, count in zip(bars, [class_counts[i] for i in sorted(CLASS_LABELS.keys())]):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,\n",
    "                 f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(\n",
    "    [class_counts[i] for i in sorted(CLASS_LABELS.keys())],\n",
    "    labels=[CLASS_LABELS[i] for i in sorted(CLASS_LABELS.keys())],\n",
    "    colors=colors,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=140,\n",
    "    wedgeprops={'edgecolor': 'white', 'linewidth': 2}\n",
    ")\n",
    "axes[1].set_title('Class Proportion', fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "plt.suptitle('Class Distribution — Davidson Hate Speech Dataset', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_01_class_distribution.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_01_class_distribution.png')\n",
    "\n",
    "# KEY INSIGHT\n",
    "print()\n",
    "print('KEY INSIGHT: The dataset is heavily imbalanced.')\n",
    "print('Offensive language (77.4%) dominates. Hate speech is only 5.8%.')\n",
    "print('=> We will need class weighting or oversampling when training the model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Annotator Agreement Analysis\n",
    "\n",
    "Each tweet was labeled by multiple annotators. High agreement = cleaner label. Low agreement = ambiguous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreement = max votes / total annotators for that tweet\n",
    "df['agreement'] = df[['hate_speech', 'offensive_language', 'neither']].max(axis=1) / df['count']\n",
    "\n",
    "print('Annotator Agreement Statistics:')\n",
    "print(df['agreement'].describe().round(3))\n",
    "print()\n",
    "print(f\"Perfect agreement (100%): {(df['agreement'] == 1.0).sum():,} tweets ({(df['agreement'] == 1.0).mean()*100:.1f}%)\")\n",
    "print(f\"Low agreement (<67%): {(df['agreement'] < 0.67).sum():,} tweets ({(df['agreement'] < 0.67).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Agreement distribution overall\n",
    "axes[0].hist(df['agreement'], bins=20, color='steelblue', edgecolor='white', linewidth=0.8)\n",
    "axes[0].axvline(df['agreement'].mean(), color='red', linestyle='--', label=f\"Mean: {df['agreement'].mean():.2f}\")\n",
    "axes[0].set_title('Annotator Agreement Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Agreement Score (max votes / total annotators)')\n",
    "axes[0].set_ylabel('Number of Tweets')\n",
    "axes[0].legend()\n",
    "\n",
    "# Agreement by class\n",
    "agreement_by_class = df.groupby('class_label')['agreement'].mean().reindex(['Hate Speech', 'Offensive', 'Neither'])\n",
    "bar_colors = [CLASS_COLORS[0], CLASS_COLORS[1], CLASS_COLORS[2]]\n",
    "bars = axes[1].bar(agreement_by_class.index, agreement_by_class.values, color=bar_colors, edgecolor='white')\n",
    "axes[1].set_title('Average Agreement by Class', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Mean Agreement Score')\n",
    "axes[1].set_ylim(0, 1.1)\n",
    "for bar, val in zip(bars, agreement_by_class.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                 f'{val:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Annotator Agreement Analysis', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_02_annotator_agreement.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_02_annotator_agreement.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Text Length Analysis\n",
    "\n",
    "Do hate speech tweets tend to be longer or shorter? Does tweet length carry a signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: text length features\n",
    "df['char_count'] = df['tweet'].str.len()\n",
    "df['word_count'] = df['tweet'].str.split().str.len()\n",
    "df['url_count'] = df['tweet'].str.count(r'http\\S+')\n",
    "df['mention_count'] = df['tweet'].str.count(r'@\\w+')\n",
    "df['hashtag_count'] = df['tweet'].str.count(r'#\\w+')\n",
    "df['exclamation_count'] = df['tweet'].str.count(r'!')\n",
    "\n",
    "print('Text Feature Statistics by Class:')\n",
    "df.groupby('class_label')[['char_count','word_count','mention_count','hashtag_count']].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Word count by class — boxplot\n",
    "class_order = ['Hate Speech', 'Offensive', 'Neither']\n",
    "palette = {name: CLASS_COLORS[cls] for cls, name in CLASS_LABELS.items()}\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df, x='class_label', y='word_count',\n",
    "    order=class_order, palette=palette, ax=axes[0],\n",
    "    flierprops={'marker': 'o', 'markersize': 2, 'alpha': 0.4}\n",
    ")\n",
    "axes[0].set_title('Word Count by Class', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Word Count')\n",
    "\n",
    "# Character count distribution — KDE per class\n",
    "for cls, name in CLASS_LABELS.items():\n",
    "    subset = df[df['class'] == cls]['char_count']\n",
    "    subset.plot.kde(ax=axes[1], label=name, color=CLASS_COLORS[cls], linewidth=2)\n",
    "axes[1].set_title('Character Count Distribution by Class', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Character Count')\n",
    "axes[1].set_xlim(0, 300)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle('Tweet Length Analysis', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_03_text_length.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_03_text_length.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Twitter Feature Analysis\n",
    "\n",
    "Mentions (@), hashtags (#), and URLs — do they differ between hate speech and other categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['mention_count', 'hashtag_count', 'url_count', 'exclamation_count']\n",
    "feature_labels = ['Mentions (@)', 'Hashtags (#)', 'URLs', 'Exclamation Marks (!)']\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "\n",
    "for ax, feat, label in zip(axes, features, feature_labels):\n",
    "    means = df.groupby('class_label')[feat].mean().reindex(class_order)\n",
    "    bars = ax.bar(class_order, means.values,\n",
    "                  color=[CLASS_COLORS[0], CLASS_COLORS[1], CLASS_COLORS[2]],\n",
    "                  edgecolor='white')\n",
    "    ax.set_title(label, fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Average Count')\n",
    "    ax.tick_params(axis='x', rotation=15)\n",
    "    for bar, val in zip(bars, means.values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{val:.2f}', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Twitter Features by Class', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_04_twitter_features.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_04_twitter_features.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Word Cloud (Optional)\n",
    "\n",
    "Visual representation of the most frequent words per class. Requires the `wordcloud` library.\n",
    "\n",
    "Install with: `pip install wordcloud`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_for_wordcloud(text):\n",
    "    \"\"\"Basic cleaning: remove URLs, mentions, special characters.\"\"\"\n",
    "    text = re.sub(r'http\\S+', '', text)       # remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)           # remove mentions\n",
    "    text = re.sub(r'RT\\s', '', text)           # remove RT prefix\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)   # keep only letters\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "if WORDCLOUD_AVAILABLE:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    wc_colors = ['Reds', 'Oranges', 'Greens']\n",
    "\n",
    "    for ax, (cls, name), cmap in zip(axes, CLASS_LABELS.items(), wc_colors):\n",
    "        text = ' '.join(df[df['class'] == cls]['tweet'].apply(clean_text_for_wordcloud))\n",
    "        wc = WordCloud(\n",
    "            width=600, height=400, background_color='white',\n",
    "            colormap=cmap, max_words=80,\n",
    "            stopwords={'rt', 'amp', 'the', 'a', 'to', 'is', 'it', 'in', 'of', 'and', 'for'}\n",
    "        ).generate(text)\n",
    "        ax.imshow(wc, interpolation='bilinear')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(name, fontsize=14, fontweight='bold', color=CLASS_COLORS[cls])\n",
    "\n",
    "    plt.suptitle('Most Frequent Words by Class', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plot_05_wordclouds.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('Saved: plot_05_wordclouds.png')\n",
    "else:\n",
    "    print('WordCloud not available. Install with: pip install wordcloud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['hate_speech', 'offensive_language', 'neither',\n",
    "                'char_count', 'word_count', 'mention_count',\n",
    "                'hashtag_count', 'url_count', 'exclamation_count', 'agreement']\n",
    "\n",
    "corr = df[numeric_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(\n",
    "    corr, mask=mask, annot=True, fmt='.2f',\n",
    "    cmap='RdBu_r', center=0, vmin=-1, vmax=1,\n",
    "    linewidths=0.5, ax=ax, cbar_kws={'shrink': 0.8}\n",
    ")\n",
    "ax.set_title('Feature Correlation Heatmap', fontsize=14, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_06_correlation.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_06_correlation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. EDA Summary & Key Insights\n",
    "\n",
    "A summary of what we found before moving to the NLP pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('EDA SUMMARY — KEY INSIGHTS')\n",
    "print('=' * 60)\n",
    "print()\n",
    "print(f'Total tweets: {len(df):,}')\n",
    "print(f'No missing values or duplicates found.')\n",
    "print()\n",
    "print('1. CLASS IMBALANCE')\n",
    "print('   Offensive language dominates (77.4%).')\n",
    "print('   Hate speech is a minority class (5.8%).')\n",
    "print('   => Use class_weight=\"balanced\" in models or oversample.')\n",
    "print()\n",
    "print('2. HIGH ANNOTATOR AGREEMENT')\n",
    "print(f\"   Mean agreement: {df['agreement'].mean():.2f}\")\n",
    "print(f\"   {(df['agreement'] == 1.0).mean()*100:.1f}% of tweets have perfect unanimous labels.\")\n",
    "print('   => Labels are reliable. Low noise dataset.')\n",
    "print()\n",
    "print('3. TEXT LENGTH')\n",
    "print(f\"   Mean word count: {df['word_count'].mean():.1f} words\")\n",
    "print(f\"   Hate speech tweets are slightly shorter on average.\")\n",
    "print('   => Word/char count may be a weak but useful feature.')\n",
    "print()\n",
    "print('4. TWITTER FEATURES')\n",
    "print('   Hate speech has more mentions (@) and fewer URLs.')\n",
    "print('   => Structural features can complement text features.')\n",
    "print()\n",
    "print('NEXT STEP: 02_nlp_pipeline.ipynb')\n",
    "print('  - Text preprocessing (clean tweets)')\n",
    "print('  - Topic modelling with BERTopic')\n",
    "print('  - Toxicity scoring with HuggingFace')\n",
    "print('  - Value sentiment analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the enriched dataset for the next notebook\n",
    "df.to_csv('labeled_data_eda.csv', index=False)\n",
    "print('Saved enriched dataset: labeled_data_eda.csv')\n",
    "print('This file includes the new features: char_count, word_count, agreement, etc.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
